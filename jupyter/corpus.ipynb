{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: python-dotenv in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (1.0.0)\n",
      "Requirement already satisfied: langchain in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (0.1.4)\n",
      "Requirement already satisfied: langchain_openai in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (0.0.5)\n",
      "Requirement already satisfied: langchain-community in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (0.0.16)\n",
      "Requirement already satisfied: langchainhub in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (0.1.14)\n",
      "Requirement already satisfied: openai in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (1.10.0)\n",
      "Requirement already satisfied: tiktoken in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (0.5.2)\n",
      "Requirement already satisfied: azure-ai-documentintelligence in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (1.0.0b1)\n",
      "Requirement already satisfied: azure-identity in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (1.14.0)\n",
      "Requirement already satisfied: azure-search-documents==11.4.0b8 in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (11.4.0b8)\n",
      "Requirement already satisfied: azure-core<2.0.0,>=1.24.0 in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (from azure-search-documents==11.4.0b8) (1.29.3)\n",
      "Requirement already satisfied: azure-common~=1.1 in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (from azure-search-documents==11.4.0b8) (1.1.28)\n",
      "Requirement already satisfied: isodate>=0.6.0 in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (from azure-search-documents==11.4.0b8) (0.6.1)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (from langchain) (2.0.25)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (from langchain) (3.8.4)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (from langchain) (4.0.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (from langchain) (0.6.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langchain-core<0.2,>=0.1.16 in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (from langchain) (0.1.16)\n",
      "Requirement already satisfied: langsmith<0.1,>=0.0.83 in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (from langchain) (0.0.83)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (from langchain) (1.25.1)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (from langchain) (1.10.12)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: types-requests<3.0.0.0,>=2.31.0.2 in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (from langchainhub) (2.31.0.20240106)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (from openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (from openai) (0.26.0)\n",
      "Requirement already satisfied: sniffio in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (from openai) (4.7.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (from tiktoken) (2023.6.3)\n",
      "Requirement already satisfied: cryptography>=2.5 in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (from azure-identity) (41.0.3)\n",
      "Requirement already satisfied: msal<2.0.0,>=1.20.0 in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (from azure-identity) (1.23.0)\n",
      "Requirement already satisfied: msal-extensions<2.0.0,>=0.3.0 in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (from azure-identity) (1.0.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
      "Requirement already satisfied: six>=1.11.0 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from azure-core<2.0.0,>=1.24.0->azure-search-documents==11.4.0b8) (1.15.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (from cryptography>=2.5->azure-identity) (1.15.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: certifi in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->openai) (2023.5.7)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (from langchain-core<0.2,>=0.1.16->langchain) (23.2)\n",
      "Requirement already satisfied: PyJWT[crypto]<3,>=1.0.0 in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (from msal<2.0.0,>=1.20.0->azure-identity) (2.8.0)\n",
      "Requirement already satisfied: portalocker<3,>=1.0 in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (from msal-extensions<2.0.0,>=0.3.0->azure-identity) (2.7.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2->langchain) (2.0.3)\n",
      "Requirement already satisfied: pycparser in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (from cffi>=1.12->cryptography>=2.5->azure-identity) (2.21)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: langchain in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (0.1.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (from langchain) (2.0.25)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (from langchain) (3.8.4)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (from langchain) (4.0.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (from langchain) (0.6.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.14 in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (from langchain) (0.0.16)\n",
      "Requirement already satisfied: langchain-core<0.2,>=0.1.16 in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (from langchain) (0.1.16)\n",
      "Requirement already satisfied: langsmith<0.1,>=0.0.83 in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (from langchain) (0.0.83)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (from langchain) (1.25.1)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (from langchain) (1.10.12)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Requirement already satisfied: anyio<5,>=3 in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (from langchain-core<0.2,>=0.1.16->langchain) (4.2.0)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (from langchain-core<0.2,>=0.1.16->langchain) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (from pydantic<3,>=1->langchain) (4.7.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2->langchain) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2->langchain) (2023.5.7)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.16->langchain) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.16->langchain) (1.2.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/miguelp/Library/Python/3.9/lib/python/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install python-dotenv langchain langchain_openai langchain-community langchainhub openai tiktoken azure-ai-documentintelligence azure-identity azure-search-documents==11.4.0b8\n",
    "! pip install langchain --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Variables\n",
    "from azure.search.documents.indexes.models import (\n",
    "    ScoringProfile,\n",
    "    SearchableField,\n",
    "    SearchField,\n",
    "    SearchFieldDataType,\n",
    "    SimpleField,\n",
    "    TextWeights,\n",
    ")\n",
    "\n",
    "# Define fileds for the index of the corpus\n",
    "\n",
    "fields = [\n",
    "    SimpleField(\n",
    "        name=\"id\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        key=True,\n",
    "        filterable=True,\n",
    "    ),\n",
    "    SearchableField(\n",
    "        name=\"content\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        searchable=True,\n",
    "    ),\n",
    "    SearchField(\n",
    "        name=\"content_vector\",\n",
    "        type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "        searchable=True,\n",
    "        vector_search_dimensions=1536,\n",
    "        vector_search_configuration=\"default\",\n",
    "    ),\n",
    "    SearchableField(\n",
    "        name=\"metadata\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        searchable=True,\n",
    "    ),\n",
    "    # Additional field to store which engine got an answer\n",
    "    SearchableField(\n",
    "        name=\"engine\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        searchable=True,\n",
    "    ),\n",
    "    # Additional field for filtering on document source\n",
    "    SimpleField(\n",
    "        name=\"source\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        filterable=True,\n",
    "    ),\n",
    "]\n",
    "\n",
    "vector_stores = [\"pdf-sample\", \"mac\"]  # List of vector stores to query for answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set environment variables\n",
    "# Called multiple times in differenct cells, you can run them independently\n",
    "from dotenv import load_dotenv\n",
    "from langchain.embeddings import AzureOpenAIEmbeddings\n",
    "import os\n",
    "\n",
    "from langchain import hub\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain_community.document_loaders import AzureAIDocumentIntelligenceLoader\n",
    "from langchain.embeddings import AzureOpenAIEmbeddings\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.text_splitter import MarkdownHeaderTextSplitter\n",
    "from langchain.vectorstores.azuresearch import AzureSearch\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "\n",
    "def set_env():\n",
    "    load_dotenv()  # take environment variables from .env.\n",
    "    os.environ[\"openai.api_type\"] = os.getenv(\"openai.api_type\")\n",
    "    os.environ[\"AZURE_OPENAI_ENDPOINT\"] = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "    os.environ[\"AZURE_OPENAI_API_KEY\"] = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "    global doc_intelligence_endpoint\n",
    "    doc_intelligence_endpoint = os.getenv(\"AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT\")\n",
    "\n",
    "    global doc_intelligence_key\n",
    "    doc_intelligence_key = os.getenv(\"AZURE_DOCUMENT_INTELLIGENCE_KEY\")\n",
    "\n",
    "    global api_version\n",
    "    api_version = os.getenv(\"openai.api_version\")\n",
    "\n",
    "    global ada_deployed_model\n",
    "    ada_deployed_model = os.getenv(\"ada\")\n",
    "\n",
    "    global gpt4_deployed_model\n",
    "    gpt4_deployed_model = os.getenv(\"gpt4\")\n",
    "\n",
    "    global vector_store_address\n",
    "    vector_store_address = os.getenv(\"AZURE_SEARCH_ENDPOINT\")\n",
    "\n",
    "    global vector_store_password\n",
    "    vector_store_password = os.getenv(\"AZURE_SEARCH_ADMIN_KEY\")\n",
    "\n",
    "\n",
    "set_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines the function to chunk and embed a document\n",
    "\n",
    "\n",
    "def process_file(file_path, index_name):\n",
    "    # Set environment variables\n",
    "    set_env()\n",
    "\n",
    "    # Initiate Azure AI Document Intelligence to load the document. You can either specify file_path or url_path to load the document.\n",
    "    loader = AzureAIDocumentIntelligenceLoader(\n",
    "        file_path=file_path,\n",
    "        api_key=doc_intelligence_key,\n",
    "        api_endpoint=doc_intelligence_endpoint,\n",
    "        api_model=\"prebuilt-layout\",\n",
    "    )\n",
    "    docs = loader.load()\n",
    "\n",
    "    # Split the document into chunks base on markdown headers.\n",
    "    headers_to_split_on = [\n",
    "        (\"#\", \"Header 1\"),\n",
    "        (\"##\", \"Header 2\"),\n",
    "        (\"###\", \"Header 3\"),\n",
    "    ]\n",
    "    text_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
    "\n",
    "    docs_string = docs[0].page_content\n",
    "    splits = text_splitter.split_text(docs_string)\n",
    "\n",
    "    print(\"Length of splits: \" + str(len(splits)))\n",
    "\n",
    "    # Embed the splitted documents and insert into Azure Search vector store\n",
    "    # openai.api_base = os.getenv(\"openai.api_base\")\n",
    "    import openai\n",
    "\n",
    "    openai.api_base = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "\n",
    "    aoai_embeddings = AzureOpenAIEmbeddings(\n",
    "        azure_deployment=ada_deployed_model,\n",
    "        openai_api_version=api_version,  # e.g., \"2023-07-01-preview\"\n",
    "    )\n",
    "\n",
    "    vector_store: AzureSearch = AzureSearch(\n",
    "        azure_search_endpoint=vector_store_address,\n",
    "        azure_search_key=vector_store_password,\n",
    "        index_name=index_name,\n",
    "        embedding_function=aoai_embeddings.embed_query,\n",
    "    )\n",
    "\n",
    "    vector_store.add_documents(documents=splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of splits: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/miguelp/Library/Python/3.9/lib/python/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.embeddings.azure_openai.AzureOpenAIEmbeddings` was deprecated in langchain-community 0.1.0 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import AzureOpenAIEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of splits: 2\n"
     ]
    }
   ],
   "source": [
    "# Let's create two indexes\n",
    "# You can comment out this two lines, after the first run.\n",
    "# After the first indexes will exist in your Azure Search service. No need to create them again.\n",
    "# Here for practicality, we create two indexes, but in the final implementation, this could be totally different vector databases/stores\n",
    "process_file(\"../sample_docs/pdf-sample.pdf\", \"pdf-sample\")\n",
    "process_file(\"../sample_docs/Mac.pdf\", \"mac\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines the function to store prompts and which index to search\n",
    "# This define our corpus of knowledge , of which embedding store (vector store or db) to search\n",
    "\n",
    "\n",
    "def feed_corpus(question, engine):\n",
    "    # Set environment variables\n",
    "    set_env()\n",
    "\n",
    "    import openai\n",
    "\n",
    "    openai.api_base = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "\n",
    "    aoai_embeddings = AzureOpenAIEmbeddings(\n",
    "        azure_deployment=ada_deployed_model,\n",
    "        openai_api_version=api_version,  # e.g., \"2023-07-01-preview\"\n",
    "    )\n",
    "\n",
    "    vector_store_address: str = os.getenv(\"AZURE_SEARCH_ENDPOINT\")\n",
    "    vector_store_password: str = os.getenv(\"AZURE_SEARCH_ADMIN_KEY\")\n",
    "\n",
    "    vector_store: AzureSearch = AzureSearch(\n",
    "        azure_search_endpoint=vector_store_address,\n",
    "        azure_search_key=vector_store_password,\n",
    "        index_name=\"corpus\",\n",
    "        embedding_function=aoai_embeddings.embed_query,\n",
    "        fields=fields,\n",
    "    )\n",
    "\n",
    "    vector_store.add_texts([question], [{\"content\": question, \"engine\": engine}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_corpus(question, top=3):\n",
    "    # Set environment variables\n",
    "    set_env()\n",
    "    import openai\n",
    "\n",
    "    openai.api_base = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "\n",
    "    aoai_embeddings = AzureOpenAIEmbeddings(\n",
    "        azure_deployment=ada_deployed_model,\n",
    "        openai_api_version=api_version,  # e.g., \"2023-07-01-preview\"\n",
    "    )\n",
    "\n",
    "    vector_store: AzureSearch = AzureSearch(\n",
    "        azure_search_endpoint=vector_store_address,\n",
    "        azure_search_key=vector_store_password,\n",
    "        index_name=\"corpus\",\n",
    "        embedding_function=aoai_embeddings.embed_query,\n",
    "        fields=fields,\n",
    "    )\n",
    "\n",
    "    retriever = vector_store.as_retriever(\n",
    "        search_type=\"similarity\", search_kwargs={\"k\": 3}\n",
    "    )\n",
    "\n",
    "    retrieved_docs = retriever.get_relevant_documents(\"<your question>\")\n",
    "\n",
    "    if len(retrieved_docs) == 0:  # The corpus does not know which DB has the answer\n",
    "        return 1, \"none\"\n",
    "\n",
    "    # there could be multiple answers, we just take the first one in this versio\n",
    "    engine = retrieved_docs[0].metadata[\n",
    "        \"engine\"\n",
    "    ]  # Our custom fields, comntains the name of the Vector Store\n",
    "\n",
    "    return 0, engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell for testing the functions\n",
    "# feed_corpus(\"Who can read a PDF file?\", \"pdf-sample\")\n",
    "# print(ask_corpus(\"Who can read a PDF file?\", 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell for setting up the RAG\n",
    "def ask_llm_rag(index_name, question):\n",
    "    # Set environment variables\n",
    "    set_env()\n",
    "\n",
    "    found = -1\n",
    "    aoai_embeddings = AzureOpenAIEmbeddings(\n",
    "        azure_deployment=ada_deployed_model,\n",
    "        openai_api_version=api_version,  # e.g., \"2023-07-01-preview\"\n",
    "    )\n",
    "    # Set environment variables\n",
    "    vector_store: AzureSearch = AzureSearch(\n",
    "        azure_search_endpoint=vector_store_address,\n",
    "        azure_search_key=vector_store_password,\n",
    "        index_name=index_name,\n",
    "        embedding_function=aoai_embeddings.embed_query,\n",
    "    )\n",
    "    retriever = vector_store.as_retriever(\n",
    "        search_type=\"similarity\", search_kwargs={\"k\": 3}\n",
    "    )\n",
    "\n",
    "    retrieved_docs = retriever.get_relevant_documents(\"<your question>\")\n",
    "\n",
    "    if len(retrieved_docs) == 0:  # This vector store does not has anwers\n",
    "        found = 1\n",
    "    else:\n",
    "        found = 0  # This vector store has anwers (success, exit code 0, unix style :) )\n",
    "\n",
    "    # Use a prompt for RAG that is checked into the LangChain prompt hub (https://smith.langchain.com/hub/rlm/rag-prompt?organizationId=989ad331-949f-4bac-9694-660074a208a7)\n",
    "    prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "    llm = AzureChatOpenAI(\n",
    "        openai_api_version=api_version,  # e.g., \"2023-07-01-preview\"\n",
    "        azure_deployment=gpt4_deployed_model,\n",
    "        temperature=0,\n",
    "    )\n",
    "\n",
    "    def format_docs(docs):\n",
    "        return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "    rag_chain_pdf = (\n",
    "        {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    answer = rag_chain_pdf.invoke(question)\n",
    "    if answer.find('The provided context does not contain information') != -1 :\n",
    "        found = 1  # This vector store does not has anwers\n",
    "    if answer.find('The context provided does not contain information') != -1 :\n",
    "        found = 1 # This vector store does not has anwers\n",
    "    # Improve this part! \n",
    "    return (found, answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell for testing the RAG\n",
    "# (found, ans) = ask_llm_rag(\"pdf-sample\", \"Who can read a PDF file?\")\n",
    "# print(ans)\n",
    "# print(found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query multiple vector stores, first the corpus, then all vector stores. Also update the corpus if the answer is found in a vector store.\n",
    "\n",
    "\n",
    "def query_with_corpus(question):\n",
    "    # Set environment variables\n",
    "    set_env()\n",
    "    print(\"  -- Asking the reference corpus first -- \")\n",
    "    (found, vector_db) = ask_corpus(question)\n",
    "    if found == 0:  # Found in that vector store (success, exit code 0, unix style :) )\n",
    "        skip_scan_alls = True\n",
    "        print(\n",
    "            \"    -- The corpus knows which vector store has information about:  \"\n",
    "            + question\n",
    "            + \" -- \"\n",
    "        )\n",
    "        print(\"    -- Querying specific vector store: \" + vector_db)\n",
    "        (found, answer) = ask_llm_rag(vector_db, question)\n",
    "        if (\n",
    "            found == 0\n",
    "        ):  # Found in that vector store (success, exit code 0, unix style :) )\n",
    "            print(\"The answer is: \" + answer)\n",
    "\n",
    "        else:\n",
    "            print(\n",
    "                \"Vector store \"\n",
    "                + vector_db\n",
    "                + \" does not have the answer for the question: \"\n",
    "                + question\n",
    "            )\n",
    "    else:\n",
    "        print(\n",
    "            \"    -- The corpus does not know which vector store has information about:  \"\n",
    "            + question\n",
    "            + \" -- \"\n",
    "        )\n",
    "        print(\"    -- Querying all vector stores -- \")\n",
    "        skip_scan_alls = False\n",
    "\n",
    "    if skip_scan_alls is False:\n",
    "        for store in vector_stores:\n",
    "            print(\n",
    "                \"  -- All vector stores will be queried, now Querying vector store: \"\n",
    "                + store\n",
    "            )\n",
    "            (found, answer) = ask_llm_rag(store, question)\n",
    "            if (\n",
    "                found == 0\n",
    "            ):  # Found in that vector store (success, exit code 0, unix style :) )\n",
    "                feed_corpus(question, store)\n",
    "                print(\n",
    "                    \"    -- The corpus has been updated: \"\n",
    "                    + store\n",
    "                    + \" has knowledge about the answer for the question: \"\n",
    "                    + question\n",
    "                    + \" -- \"\n",
    "                )\n",
    "                print(\"The answer is: \" + answer)\n",
    "            else:\n",
    "                print(\n",
    "                    \"    --  Vector store \"\n",
    "                    + store\n",
    "                    + \" does not have the answer for the question: \"\n",
    "                    + question\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- First iteration -- \n",
      "  -- Asking the reference corpus first -- \n",
      "    -- The corpus does not know which vector store has information about:  Describe characteristics of an iMac G3? -- \n",
      "    -- Querying all vector stores -- \n",
      "  -- All vector stores will be queried, now Querying vector store: pdf-sample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/miguelp/Library/Python/3.9/lib/python/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.azure_openai.AzureChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import AzureChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    --  Vector store pdf-sample does not have the answer for the question: Describe characteristics of an iMac G3?\n",
      "  -- All vector stores will be queried, now Querying vector store: mac\n",
      "    -- The corpus has been updated: mac has knowledge about the answer for the question: Describe characteristics of an iMac G3? -- \n",
      "The answer is: The iMac G3, introduced by Apple in 1998, was a significant product that helped push the Mac mainstream. It was part of a focused product oversight by Steve Jobs after his return to Apple in 1996. The iMac G3 was part of the transition to the OS X operating system and the shift to Intel processors from 2005 to 2006.\n",
      "-- Second iteration -- \n",
      "  -- Asking the reference corpus first -- \n",
      "    -- The corpus knows which vector store has information about:  Describe characteristics of an iMac G3? -- \n",
      "    -- Querying specific vector store: mac\n",
      "The answer is: The iMac G3, introduced by Apple in 1998, was a significant product that helped push the Mac mainstream. It was part of a focused product oversight by Steve Jobs after his return to Apple in 1996. The iMac G3 was part of the transition to the OS X operating system and the shift to Intel processors from 2005 to 2006.\n"
     ]
    }
   ],
   "source": [
    "# Multiple index (in the future) multile vector stores\n",
    "# The corpus is the vector store that contains which vector store has the answer\n",
    "\n",
    "# We will do two iterartions\n",
    "# First interation our corupus will be empty, we will need to query al vector stores\n",
    "# Second iteration we will have a corpus and we will know which vector store has the answer\n",
    "\n",
    "# First iteration\n",
    "print(\"-- First iteration -- \")\n",
    "query_with_corpus(\"Describe characteristics of an iMac G3?\")\n",
    "\n",
    "print(\"-- Second iteration -- \")\n",
    "# Second iteration\n",
    "# We expected to corpus to know which vector store has the answer, avoiding querying all vector stores\n",
    "query_with_corpus(\"Describe characteristics of an iMac G3?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
